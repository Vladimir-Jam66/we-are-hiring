# 🌸 小红书 AI Lab · 我们在寻找「让 AI 更懂人心」的 Post-Training 伙伴
「hi lab」Join our AI team! 🚀 We're hiring Post-training Engineers, RLHF Researchers &amp; more.
> “技术不是冰冷的参数，而是理解亿万用户细微情绪的桥梁。”  
> —— 小红书 AI Lab 价值观
## 🌟 我们在做什么？  
不是只调 loss，而是让模型真正 **「会共情、守边界、有分寸」** ——
| 方向 | 我们的探索 |
|------|-----------|
| 📚 **SFT 增强** | 结合社区真实笔记（非合成数据），让模型学会「小红书式表达」：亲切、有信息量、不浮夸 |
| ⚖️ **Reward Modeling** | 构建多维反馈：不止「有用」，还要「安全」「有温度」「不制造焦虑」|
| 🧠 **RLHF / DPO / GRPO** | 优化人类偏好对齐效率，**标注成本降低 70%+**，上线速度提升 3 倍 |
| 🔍 **价值观对齐** | 探索「反容貌焦虑」「反信息茧房」的模型干预策略（已落地社区治理）|
| 🧪 **Evaluation** | 自研 **X-Eval** 评估体系：覆盖知识性、安全性、情感适配度、文化敏感性 |

✅ 成果：  
- 支撑「AI 笔记助手」「AI 拍摄建议」等亿级 DAU 功能  
- 多项技术沉淀为内部工具链，**鼓励开源反哺社区**

---

## 🧑‍💻 期待这样的你

### 🌱 我们欢迎多种背景：
- 🎓 应届博士：发过 RLHF/DPO 相关论文，**愿把 research 落到真实场景**  
- 👨‍💻 社招工程师：有 SFT/RLHF 全流程 pipeline 经验，**debug 过 reward hacking、collapse、over-optimization**  
- 🌍 跨界人才：做过 NLP/推荐/对话系统，**对「人-AI 协同」有强烈兴趣**

### ✅ 核心特质（比学历更重要！）：
- 对「模型行为」敏感：能从 bad case 反推 training/inference 问题  
- 拥抱模糊性：Post-training 没有标准答案，我们边做边定义 best practice  
- 有人文视角：理解「技术决策」如何影响用户心理（例：为什么不说“你该减肥”？）

---

## 🎁 为什么选择我们？

|  |  |
|---|---|
| 🌈 **技术 × 人文 × 产品 三角协同** | 算法工程师与社区运营、心理学顾问、产品经理每周共创 |
| 🧪 **真·大规模实验场** | 每天亿级真实用户反馈，快速验证你的 idea 是否「被需要」 |
| 📚 **成长支持** | • 技术大会全额赞助（NeurIPS/ACL/ICLR）<br>• 内部「AI 沙龙」每月 1 期<br>• 与清华、复旦、港中文联合课题 |
| 🏡 **工作方式** | • 弹性打卡 + 每周三「无会日」<br>• 支持远程办公（需 occasional onsite）<br>• **拒绝 PUA，我们信「长期主义」** |

---

## 📬 如何加入？

### 方式 1：直接投递（推荐！）
📧 联系方式：**`19857517746`**  
📝 标题格式：  
`[Post-train] 姓名 - 方向（例：RLHF / 安全对齐 / 评估体系）`  

📎 请附：
- 简历（PDF）
- **任选其一**：  
  - GitHub 主页  
  - 技术博客链接  
  - 一段「你见过最离谱的模型幻觉」分析  
  - （应届生）课程/竞赛项目简述
